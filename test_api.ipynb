{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "022bf917",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chbrai/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/var/folders/dw/lrwthtn92hbcrspt70mlprgm0000gn/T/ipykernel_96965/2285697829.py:12: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
      "/var/folders/dw/lrwthtn92hbcrspt70mlprgm0000gn/T/ipykernel_96965/2285697829.py:27: LangChainDeprecationWarning: The class `ChatOllama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import ChatOllama``.\n",
      "  llm = ChatOllama(model=\"mistral_prompt\",temperature=1)\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain.schema import Document\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "import os\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "if os.path.exists(\"sii_qa_index\"):\n",
    "    db = FAISS.load_local(\"sii_qa_index\", embedding_model, allow_dangerous_deserialization=True)\n",
    "else:\n",
    "    with open('faq_data.json', 'r', encoding='utf-8') as f:\n",
    "        qa_pairs = json.load(f)\n",
    "\n",
    "    documents = [Document(page_content=f\"Q: {q}\\nA: {a}\") for q, a in qa_pairs.items()]\n",
    "    db = FAISS.from_documents(documents, embedding_model)\n",
    "    db.save_local(\"sii_qa_index\")\n",
    "\n",
    "retriever = db.as_retriever()\n",
    "\n",
    "\n",
    "llm = ChatOllama(model=\"mistral_prompt\",temperature=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85627d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dw/lrwthtn92hbcrspt70mlprgm0000gn/T/ipykernel_96965/2391637312.py:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory=ConversationBufferMemory()\n"
     ]
    }
   ],
   "source": [
    "memory=ConversationBufferMemory()\n",
    "rag_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    return_source_documents=False,\n",
    "    memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76f6b7ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'Hi I am Vasu',\n",
       " 'history': '',\n",
       " 'result': ' Hello Vasu! It seems you are interacting with the Study In India Assistant. The assistant introduced itself as the \"Study In India Assistant\" in our previous conversation. If you have any questions about studying in India or need assistance, feel free to ask.ðŸ˜Š'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke({\"query\": \"Hi I am Vasu\"})#result = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b31c2b3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': \"What's my name\",\n",
       " 'history': 'Human: Hi I am Vasu\\nAI:  Hello Vasu! It seems you are interacting with the Study In India Assistant. The assistant introduced itself as the \"Study In India Assistant\" in our previous conversation. If you have any questions about studying in India or need assistance, feel free to ask.ðŸ˜Š',\n",
       " 'result': \" My name is Study In India Assistant, I'm here to assist you personally ðŸ˜Š\"}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke({\"query\": \"What's my name\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8df181f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Hi I am Vasu\n",
      "AI:  Hello Vasu! It seems you are interacting with the Study In India Assistant. The assistant introduced itself as the \"Study In India Assistant\" in our previous conversation. If you have any questions about studying in India or need assistance, feel free to ask.ðŸ˜Š\n",
      "Human: What's my name\n",
      "AI:  My name is Study In India Assistant, I'm here to assist you personally ðŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "print(rag_chain.memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9cd24267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'What do I do?',\n",
       " 'history': 'Human: Hi I am Vasu\\nAI:  Hello Vasu! It seems you are interacting with the Study In India Assistant. The assistant introduced itself as the \"Study In India Assistant\" in our previous conversation. If you have any questions about studying in India or need assistance, feel free to ask.ðŸ˜Š\\nHuman: What\\'s my name\\nAI:  My name is Study In India Assistant, I\\'m here to assist you personally ðŸ˜Š',\n",
       " 'result': \"1. To know when the next counseling round is, you can ask the organization handling the process or check their official website for updates.\\n2. Yes, you can update your course preferences at any time before the application deadlines for each round. However, it's best to check with the organization first to ensure this option is still available.\\n3. If your application is rejected, you'll get a chance to reapply during the next round of counseling. It is essential to re-check your eligibility and modify your course preferences if necessary.\\n4. I don't have information about whether feedback on rejections will be provided or not. You should contact the organization for details regarding this.\\n5. Typically, appeals process varies by institution, so it would be best to check with the organization directly if you wish to appeal a decision.\\n6. No, there is no standard policy to inform applicants why their application was rejected. Again, contact the organization for more information on this matter.\"}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke({\"query\":\"What do I do?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d6f081",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chbrai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
